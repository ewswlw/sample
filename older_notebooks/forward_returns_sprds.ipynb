{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bloomberg_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Import custom modules with an alias\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbloomberg_data\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbd\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtr\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bloomberg_data'"
     ]
    }
   ],
   "source": [
    "import vectorbt as vbt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "from xbbg import blp\n",
    "import os\n",
    "import quantstats as qs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import custom modules with an alias\n",
    "import bloomberg_data as bd\n",
    "import transformations as tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 12:43:43,205 - INFO - Successfully retrieved data for ticker: .MIDERCAD U Index\n",
      "2024-07-03 12:43:43,870 - INFO - Successfully retrieved data for ticker: .CADIG F Index\n",
      "2024-07-03 12:43:44,229 - INFO - Successfully retrieved data for ticker: VIX Index\n",
      "2024-07-03 12:43:44,834 - INFO - Successfully retrieved data for ticker: .HYUSER U Index\n",
      "2024-07-03 12:43:45,471 - INFO - Successfully retrieved data for ticker: .IGUSER U Index\n",
      "2024-07-03 12:43:45,480 - INFO - Merged 5 dataframes using inner method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            cad_ig_er_index  cad_ig_sprds    vix  us_hy_er_index  \\\n",
      "2002-11-29           1.0143       69.8153  27.50          0.4183   \n",
      "2002-12-31           1.0146       77.3398  28.62          0.4134   \n",
      "2003-01-31           1.0155       74.8880  31.17          0.4285   \n",
      "2003-02-28           1.0159      106.9295  29.63          0.4265   \n",
      "2003-03-31           1.0142      117.3892  29.15          0.4406   \n",
      "...                     ...           ...    ...             ...   \n",
      "2024-06-26           1.3935      120.6997  12.55          1.1236   \n",
      "2024-06-27           1.3933      120.9534  12.24          1.1215   \n",
      "2024-06-28           1.3925      120.2679  12.44          1.1270   \n",
      "2024-07-01           1.3925      121.6130  12.22          1.1319   \n",
      "2024-07-02           1.3958      122.1411  12.03          1.1290   \n",
      "\n",
      "            us_ig_er_index  \n",
      "2002-11-29          1.0150  \n",
      "2002-12-31          1.0195  \n",
      "2003-01-31          1.0269  \n",
      "2003-02-28          1.0303  \n",
      "2003-03-31          1.0351  \n",
      "...                    ...  \n",
      "2024-06-26          1.4201  \n",
      "2024-06-27          1.4207  \n",
      "2024-06-28          1.4199  \n",
      "2024-07-01          1.4205  \n",
      "2024-07-02          1.4228  \n",
      "\n",
      "[2035 rows x 5 columns]\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2035 entries, 2002-11-29 to 2024-07-02\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cad_ig_er_index  2035 non-null   float64\n",
      " 1   cad_ig_sprds     2035 non-null   float64\n",
      " 2   vix              2035 non-null   float64\n",
      " 3   us_hy_er_index   2035 non-null   float64\n",
      " 4   us_ig_er_index   2035 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 95.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Getting the data from the bloomberg_data module \n",
    "tickers = ['.MIDERCAD U Index', '.CADIG F Index', 'VIX Index','.HYUSER U Index','.IGUSER U Index']\n",
    "fields = [['PX_LAST'], ['PX_LAST'], ['PX_LAST'],['PX_LAST'], ['PX_LAST']]\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2025-12-31'\n",
    "column_names = [['cad_ig_er_index'], ['cad_ig_sprds'], ['vix'], ['us_hy_er_index'], ['us_ig_er_index']]\n",
    "frequencies = ['D', 'D', 'D','D','D']  # You can edit the frequency for each ticker here\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for ticker, field, col_name, freq in zip(tickers, fields, column_names, frequencies):\n",
    "    df = bd.get_single_ticker_data(ticker, field, start_date, end_date, freq=freq, column_names=col_name)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Getting risk-free index\n",
    "#rate_df = bd.get_single_ticker_data('GCAN3M Index', ['PX_LAST'], start_date, end_date)\n",
    "#risk_free_idx = tr.risk_free_index(rate_df,col_name=\"risk_free\")  # Ensure the default col_name is applied\n",
    "\n",
    "# Merge all dataframes including the risk-free index\n",
    "merged_data = bd.merge_dataframes(dataframes)\n",
    "#merged_data = bd.merge_dataframes([merged_data, risk_free_idx])\n",
    "\n",
    "# Print the final merged data and its information\n",
    "print(merged_data)\n",
    "print('----------------------------------------------------------------')\n",
    "print('----------------------------------------------------------------')\n",
    "print(merged_data.info())\n",
    "\n",
    "# Rename\n",
    "data= merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2035 entries, 2002-11-29 to 2024-07-02\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cad_ig_er_index  2035 non-null   float64\n",
      " 1   cad_ig_sprds     2035 non-null   float64\n",
      " 2   vix              2035 non-null   float64\n",
      " 3   us_hy_er_index   2035 non-null   float64\n",
      " 4   us_ig_er_index   2035 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 95.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (638, 42)\n",
      "y_train shape: (638,)\n",
      "X_test shape: (1327, 42)\n",
      "y_test shape: (1327,)\n",
      "Selected features: Index(['cad_ig_sprds', 'us_hy_er_index', 'cad_ig_sprds_last',\n",
      "       'us_hy_er_index_20d_pct_change', 'us_hy_er_index_50d_pct_change',\n",
      "       'cad_ig_sprds_50d_pct_change', 'us_ig_er_index_20d_pct_change',\n",
      "       'us_ig_er_index_50d_pct_change'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import vectorbt as vbt\n",
    "\n",
    "# Load your dataset (assuming it's already loaded as 'data')\n",
    "\n",
    "# % Diff of the Last Value vs 10/20/50 Period MA for each index\n",
    "for col in ['us_hy_er_index', 'cad_ig_sprds', 'vix', 'us_ig_er_index']:\n",
    "    data[f'{col}_10d_diff'] = (data[col] - data[col].rolling(window=10).mean()) / data[col].rolling(window=10).mean()\n",
    "    data[f'{col}_20d_diff'] = (data[col] - data[col].rolling(window=20).mean()) / data[col].rolling(window=20).mean()\n",
    "    data[f'{col}_50d_diff'] = (data[col] - data[col].rolling(window=50).mean()) / data[col].rolling(window=50).mean()\n",
    "\n",
    "# Last values of cad_ig_sprds and vix\n",
    "data['cad_ig_sprds_last'] = data['cad_ig_sprds']\n",
    "data['vix_last'] = data['vix']\n",
    "\n",
    "# % Change Over the Last 10/20/50 Periods for each index\n",
    "for col in ['us_hy_er_index', 'cad_ig_sprds', 'vix', 'us_ig_er_index']:\n",
    "    data[f'{col}_10d_pct_change'] = data[col].pct_change(periods=10)\n",
    "    data[f'{col}_20d_pct_change'] = data[col].pct_change(periods=20)\n",
    "    data[f'{col}_50d_pct_change'] = data[col].pct_change(periods=50)\n",
    "\n",
    "# Volatility of the % Change Over the Last 10/20/50 Periods for each index\n",
    "for col in ['us_hy_er_index', 'cad_ig_sprds', 'vix', 'us_ig_er_index']:\n",
    "    data[f'{col}_10d_vol'] = data[col].pct_change().rolling(window=10).std()\n",
    "    data[f'{col}_20d_vol'] = data[col].pct_change().rolling(window=20).std()\n",
    "    data[f'{col}_50d_vol'] = data[col].pct_change().rolling(window=50).std()\n",
    "\n",
    "# Calculate future returns for cad_ig_er_index\n",
    "data['cad_ig_er_index_return'] = data['cad_ig_er_index'].pct_change(periods=20).shift(-20)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Ensure there are no missing values left\n",
    "assert data.isna().sum().sum() == 0, \"There are still missing values in the data.\"\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train = data[:'2018-12-31']\n",
    "test = data['2019-01-01':]\n",
    "\n",
    "X_train = train.drop(columns=['cad_ig_er_index', 'cad_ig_er_index_return'])\n",
    "y_train = train['cad_ig_er_index_return']\n",
    "X_test = test.drop(columns=['cad_ig_er_index', 'cad_ig_er_index_return'])\n",
    "y_test = test['cad_ig_er_index_return']\n",
    "\n",
    "# Check the shapes to ensure we have data\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Select features based on importance\n",
    "sfm = SelectFromModel(rf, threshold='mean')\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "selected_features = X_train.columns[sfm.get_support()]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-02-28 00:00:00\n",
      "2024-06-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Verify the date range of the dataset\n",
    "print(data.index.min())\n",
    "print(data.index.max())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
